{
    "label": "InfluxDB_r=2h-chained_atDrop_XXL_e=1000_pl=20_hst=0",
    "mean_squared_error": -1,
    "runtimes": "Training: 260.19 seconds",
    "length_train_dataset": 196091,
    "length_test_dataset": 1,
    "parameters": "Epochs: 1000, hyperparameters: Hyperparamters(gradient_clip_val=6.9953515571, hidden_continuous_size=40, dropout=0.1558743686, attention_head_size=3, learning_rate=0.0039810717, accelerator='auto', hidden_size=70)",
    "prediction": "Prediction(output=Output(prediction=tensor([[[0.0000, 3.4037, 5.7225, 6.8558, 7.3402, 7.7793, 8.9194],\n         [0.0000, 3.4290, 5.8200, 7.0110, 7.5572, 7.9883, 9.1396],\n         [0.0000, 3.3540, 5.7535, 7.0700, 7.6876, 8.1177, 9.3189],\n         [0.0000, 3.2742, 5.6503, 7.0611, 7.7339, 8.1719, 9.4080],\n         [0.0000, 3.1873, 5.5237, 7.0129, 7.7344, 8.1882, 9.4504],\n         [0.0000, 3.0627, 5.3477, 6.9306, 7.7100, 8.1900, 9.4854],\n         [0.0000, 2.8566, 5.0775, 6.7971, 7.6607, 8.1849, 9.5365],\n         [0.0000, 2.5050, 4.6465, 6.5655, 7.5593, 8.1636, 9.6079],\n         [0.0000, 1.9509, 3.9932, 6.1547, 7.3365, 8.0818, 9.6491],\n         [0.0000, 1.2783, 3.1942, 5.5459, 6.9348, 7.8740, 9.5373],\n         [0.0000, 0.7561, 2.5287, 4.9431, 6.4704, 7.5783, 9.2540],\n         [0.0000, 0.4882, 2.1410, 4.5342, 6.1128, 7.3166, 8.9539],\n         [0.0000, 0.3773, 1.9478, 4.2902, 5.8730, 7.1215, 8.7123],\n         [0.0000, 0.3386, 1.8527, 4.1323, 5.7002, 6.9674, 8.5132],\n         [0.0000, 0.3344, 1.8066, 4.0152, 5.5598, 6.8315, 8.3332],\n         [0.0000, 0.3499, 1.7885, 3.9199, 5.4363, 6.7029, 8.1600],\n         [0.0000, 0.3796, 1.7898, 3.8394, 5.3240, 6.5776, 7.9894],\n         [0.0000, 0.4207, 1.8064, 3.7713, 5.2211, 6.4552, 7.8208],\n         [0.0000, 0.4719, 1.8360, 3.7154, 5.1277, 6.3365, 7.6560],\n         [0.0000, 0.5323, 1.8766, 3.6714, 5.0443, 6.2233, 7.4974]]],\n       device='cuda:0'), encoder_attention=tensor([[[[1.3851e-02, 7.1732e-02, 1.1232e-01,  ..., 6.3816e-06,\n           4.5734e-06, 5.0472e-06],\n          [2.8437e-02, 3.5541e-02, 3.8401e-02,  ..., 7.1163e-03,\n           6.4774e-03, 6.6647e-03],\n          [5.7483e-02, 6.2584e-02, 6.1092e-02,  ..., 4.6813e-03,\n           4.5303e-03, 4.5782e-03],\n          [7.1117e-02, 7.0090e-02, 6.8229e-02,  ..., 2.8517e-03,\n           2.7336e-03, 2.7690e-03]],\n\n         [[1.3757e-02, 7.1708e-02, 1.1261e-01,  ..., 6.7085e-06,\n           4.8191e-06, 5.3147e-06],\n          [2.6646e-02, 3.2730e-02, 3.5139e-02,  ..., 7.6363e-03,\n           6.9853e-03, 7.1768e-03],\n          [5.5979e-02, 6.1167e-02, 5.9757e-02,  ..., 4.8245e-03,\n           4.6630e-03, 4.7156e-03],\n          [6.8260e-02, 6.6400e-02, 6.4198e-02,  ..., 3.2901e-03,\n           3.1627e-03, 3.2018e-03]],\n\n         [[1.3581e-02, 7.1635e-02, 1.1298e-01,  ..., 6.7100e-06,\n           4.8207e-06, 5.3165e-06],\n          [2.6614e-02, 3.2518e-02, 3.4842e-02,  ..., 7.6474e-03,\n           7.0171e-03, 7.2023e-03],\n          [5.4817e-02, 6.0115e-02, 5.8838e-02,  ..., 4.6941e-03,\n           4.5330e-03, 4.5853e-03],\n          [6.7142e-02, 6.5337e-02, 6.3071e-02,  ..., 3.4229e-03,\n           3.2934e-03, 3.3337e-03]],\n\n         ...,\n\n         [[1.0508e-02, 6.9814e-02, 1.1918e-01,  ..., 4.1251e-06,\n           2.8351e-06, 3.1724e-06],\n          [4.2293e-02, 5.8538e-02, 6.6208e-02,  ..., 2.7753e-03,\n           2.5380e-03, 2.6048e-03],\n          [4.5849e-02, 5.2188e-02, 5.2545e-02,  ..., 1.2057e-03,\n           1.1610e-03, 1.1699e-03],\n          [6.9249e-02, 8.6133e-02, 8.9962e-02,  ..., 6.1854e-04,\n           5.8047e-04, 5.9179e-04]],\n\n         [[1.0426e-02, 6.9737e-02, 1.1932e-01,  ..., 4.0332e-06,\n           2.7655e-06, 3.0968e-06],\n          [4.1815e-02, 5.8073e-02, 6.5817e-02,  ..., 2.7353e-03,\n           2.4984e-03, 2.5653e-03],\n          [4.4648e-02, 5.0881e-02, 5.1286e-02,  ..., 1.1366e-03,\n           1.0946e-03, 1.1028e-03],\n          [6.8603e-02, 8.5898e-02, 8.9968e-02,  ..., 5.6978e-04,\n           5.3405e-04, 5.4462e-04]],\n\n         [[1.0357e-02, 6.9673e-02, 1.1943e-01,  ..., 3.9536e-06,\n           2.7052e-06, 3.0313e-06],\n          [4.1270e-02, 5.7488e-02, 6.5276e-02,  ..., 2.7025e-03,\n           2.4656e-03, 2.5326e-03],\n          [4.3394e-02, 4.9501e-02, 4.9943e-02,  ..., 1.0738e-03,\n           1.0343e-03, 1.0418e-03],\n          [6.7908e-02, 8.5528e-02, 8.9809e-02,  ..., 5.2839e-04,\n           4.9471e-04, 5.0464e-04]]]], device='cuda:0'), decoder_attention=tensor([[[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00],\n          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00],\n          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00],\n          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00]],\n\n         [[4.4028e-06, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00],\n          [1.4717e-03, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00],\n          [2.0024e-02, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00],\n          [1.1180e-02, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00]],\n\n         [[4.4435e-06, 3.0889e-06, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00],\n          [1.5556e-03, 1.3475e-03, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00],\n          [1.9659e-02, 2.0138e-02, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00],\n          [1.0168e-02, 1.0595e-02, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00]],\n\n         ...,\n\n         [[2.7889e-06, 1.9646e-06, 1.5452e-06,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00],\n          [1.1105e-03, 1.0132e-03, 1.0345e-03,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00],\n          [1.3280e-02, 1.2209e-02, 1.1726e-02,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00],\n          [2.3033e-03, 2.4232e-03, 2.5436e-03,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00]],\n\n         [[2.7255e-06, 1.9191e-06, 1.5093e-06,  ..., 1.3385e-06,\n           0.0000e+00, 0.0000e+00],\n          [1.0833e-03, 9.8878e-04, 1.0111e-03,  ..., 8.8285e-03,\n           0.0000e+00, 0.0000e+00],\n          [1.2959e-02, 1.1872e-02, 1.1389e-02,  ..., 2.2152e-02,\n           0.0000e+00, 0.0000e+00],\n          [2.2717e-03, 2.3927e-03, 2.5175e-03,  ..., 5.1729e-03,\n           0.0000e+00, 0.0000e+00]],\n\n         [[2.6693e-06, 1.8789e-06, 1.4776e-06,  ..., 1.3142e-06,\n           1.5424e-06, 0.0000e+00],\n          [1.0593e-03, 9.6720e-04, 9.9043e-04,  ..., 8.8860e-03,\n           9.6559e-03, 0.0000e+00],\n          [1.2625e-02, 1.1530e-02, 1.1049e-02,  ..., 2.2089e-02,\n           2.3573e-02, 0.0000e+00],\n          [2.2504e-03, 2.3729e-03, 2.5023e-03,  ..., 5.3735e-03,\n           5.5269e-03, 0.0000e+00]]]], device='cuda:0'), static_variables=tensor([[[0.0613, 0.5402, 0.3985]]], device='cuda:0'), encoder_variables=tensor([[[[0.0691, 0.0957, 0.8352]],\n\n         [[0.0688, 0.0963, 0.8349]],\n\n         [[0.0688, 0.0963, 0.8349]],\n\n         [[0.0696, 0.0948, 0.8356]],\n\n         [[0.0690, 0.0959, 0.8351]],\n\n         [[0.0701, 0.0939, 0.8359]],\n\n         [[0.0694, 0.0952, 0.8354]],\n\n         [[0.0695, 0.0951, 0.8355]],\n\n         [[0.0700, 0.0941, 0.8359]],\n\n         [[0.0701, 0.0940, 0.8359]],\n\n         [[0.0702, 0.0938, 0.8360]],\n\n         [[0.0731, 0.0894, 0.8375]],\n\n         [[0.0750, 0.0870, 0.8380]],\n\n         [[0.0759, 0.0858, 0.8382]],\n\n         [[0.0763, 0.0854, 0.8383]],\n\n         [[0.0758, 0.0859, 0.8382]],\n\n         [[0.0775, 0.0840, 0.8385]],\n\n         [[0.0768, 0.0849, 0.8384]],\n\n         [[0.0777, 0.0839, 0.8385]],\n\n         [[0.0766, 0.0851, 0.8383]],\n\n         [[0.0770, 0.0846, 0.8384]],\n\n         [[0.0770, 0.0846, 0.8384]],\n\n         [[0.0772, 0.0844, 0.8384]],\n\n         [[0.0782, 0.0833, 0.8385]],\n\n         [[0.0772, 0.0843, 0.8384]],\n\n         [[0.0782, 0.0833, 0.8385]],\n\n         [[0.0788, 0.0827, 0.8385]],\n\n         [[0.0782, 0.0833, 0.8385]],\n\n         [[0.0786, 0.0829, 0.8385]],\n\n         [[0.0788, 0.0827, 0.8385]],\n\n         [[0.0792, 0.0823, 0.8385]],\n\n         [[0.0796, 0.0818, 0.8385]],\n\n         [[0.0793, 0.0822, 0.8385]],\n\n         [[0.0788, 0.0826, 0.8385]],\n\n         [[0.0796, 0.0819, 0.8385]],\n\n         [[0.0803, 0.0812, 0.8385]],\n\n         [[0.0802, 0.0813, 0.8385]],\n\n         [[0.0822, 0.0795, 0.8383]],\n\n         [[0.0822, 0.0795, 0.8383]],\n\n         [[0.0830, 0.0788, 0.8382]],\n\n         [[0.0820, 0.0797, 0.8383]],\n\n         [[0.0845, 0.0776, 0.8379]],\n\n         [[0.0835, 0.0784, 0.8381]],\n\n         [[0.0855, 0.0769, 0.8377]],\n\n         [[0.0841, 0.0779, 0.8380]],\n\n         [[0.0850, 0.0772, 0.8378]],\n\n         [[0.0842, 0.0778, 0.8380]],\n\n         [[0.0867, 0.0760, 0.8373]],\n\n         [[0.0857, 0.0767, 0.8376]],\n\n         [[0.0845, 0.0776, 0.8379]],\n\n         [[0.0860, 0.0764, 0.8375]],\n\n         [[0.0866, 0.0760, 0.8374]],\n\n         [[0.0870, 0.0757, 0.8372]],\n\n         [[0.0878, 0.0752, 0.8370]],\n\n         [[0.0888, 0.0745, 0.8367]],\n\n         [[0.0874, 0.0754, 0.8371]],\n\n         [[0.0885, 0.0748, 0.8368]],\n\n         [[0.0898, 0.0739, 0.8363]],\n\n         [[0.0887, 0.0746, 0.8367]],\n\n         [[0.0889, 0.0745, 0.8366]],\n\n         [[0.0886, 0.0747, 0.8367]],\n\n         [[0.0894, 0.0742, 0.8365]],\n\n         [[0.0891, 0.0744, 0.8366]],\n\n         [[0.0893, 0.0742, 0.8365]],\n\n         [[0.0900, 0.0738, 0.8362]],\n\n         [[0.0904, 0.0735, 0.8361]],\n\n         [[0.0906, 0.0734, 0.8360]],\n\n         [[0.0908, 0.0733, 0.8359]],\n\n         [[0.0928, 0.0721, 0.8351]],\n\n         [[0.0915, 0.0729, 0.8357]],\n\n         [[0.0922, 0.0725, 0.8353]],\n\n         [[0.0929, 0.0721, 0.8350]],\n\n         [[0.0918, 0.0727, 0.8355]],\n\n         [[0.0902, 0.0736, 0.8361]],\n\n         [[0.0892, 0.0743, 0.8365]],\n\n         [[0.0897, 0.0740, 0.8364]],\n\n         [[0.0901, 0.0737, 0.8362]],\n\n         [[0.0916, 0.0728, 0.8356]],\n\n         [[0.0909, 0.0733, 0.8359]],\n\n         [[0.0912, 0.0730, 0.8358]]]], device='cuda:0'), decoder_variables=tensor([[[[0.8167, 0.1833]],\n\n         [[0.8167, 0.1833]],\n\n         [[0.8167, 0.1833]],\n\n         [[0.8167, 0.1833]],\n\n         [[0.8167, 0.1833]],\n\n         [[0.8167, 0.1833]],\n\n         [[0.8167, 0.1833]],\n\n         [[0.8167, 0.1833]],\n\n         [[0.8167, 0.1833]],\n\n         [[0.8167, 0.1833]],\n\n         [[0.8167, 0.1833]],\n\n         [[0.8167, 0.1833]],\n\n         [[0.8167, 0.1833]],\n\n         [[0.8167, 0.1833]],\n\n         [[0.8167, 0.1833]],\n\n         [[0.8167, 0.1833]],\n\n         [[0.8167, 0.1833]],\n\n         [[0.8167, 0.1833]],\n\n         [[0.8167, 0.1833]],\n\n         [[0.8167, 0.1833]]]], device='cuda:0'), decoder_lengths=tensor([20], device='cuda:0'), encoder_lengths=tensor([80], device='cuda:0')), x={'encoder_cat': tensor([], device='cuda:0', size=(1, 80, 0), dtype=torch.int64), 'encoder_cont': tensor([[[ 1.0000,  0.6694, -0.1568,  1.7306, -1.0000, -1.9393],\n         [ 1.0000,  0.6694, -0.1568,  1.7307, -0.9875, -2.0395],\n         [ 1.0000,  0.6694, -0.1568,  1.7307, -0.9750, -2.0482],\n         [ 1.0000,  0.6694, -0.1568,  1.7307, -0.9625, -1.8654],\n         [ 1.0000,  0.6694, -0.1568,  1.7307, -0.9500, -2.0177],\n         [ 1.0000,  0.6694, -0.1568,  1.7307, -0.9375, -1.7652],\n         [ 1.0000,  0.6694, -0.1568,  1.7308, -0.9250, -1.9524],\n         [ 1.0000,  0.6694, -0.1568,  1.7308, -0.9125, -1.9437],\n         [ 1.0000,  0.6694, -0.1568,  1.7308, -0.9000, -1.8218],\n         [ 1.0000,  0.6694, -0.1568,  1.7308, -0.8875, -1.8218],\n         [ 1.0000,  0.6694, -0.1568,  1.7308, -0.8750, -1.8044],\n         [ 1.0000,  0.6694, -0.1568,  1.7308, -0.8625, -1.1951],\n         [ 1.0000,  0.6694, -0.1568,  1.7309, -0.8500, -0.8469],\n         [ 1.0000,  0.6694, -0.1568,  1.7309, -0.8375, -0.6728],\n         [ 1.0000,  0.6694, -0.1568,  1.7309, -0.8250, -0.6162],\n         [ 1.0000,  0.6694, -0.1568,  1.7309, -0.8125, -0.7163],\n         [ 1.0000,  0.6694, -0.1568,  1.7309, -0.8000, -0.4203],\n         [ 1.0000,  0.6694, -0.1568,  1.7309, -0.7875, -0.5683],\n         [ 1.0000,  0.6694, -0.1568,  1.7310, -0.7750, -0.4203],\n         [ 1.0000,  0.6694, -0.1568,  1.7310, -0.7625, -0.6336],\n         [ 1.0000,  0.6694, -0.1568,  1.7310, -0.7500, -0.5727],\n         [ 1.0000,  0.6694, -0.1568,  1.7310, -0.7375, -0.5727],\n         [ 1.0000,  0.6694, -0.1568,  1.7310, -0.7250, -0.5509],\n         [ 1.0000,  0.6694, -0.1568,  1.7311, -0.7125, -0.3899],\n         [ 1.0000,  0.6694, -0.1568,  1.7311, -0.7000, -0.5727],\n         [ 1.0000,  0.6694, -0.1568,  1.7311, -0.6875, -0.4203],\n         [ 1.0000,  0.6694, -0.1568,  1.7311, -0.6750, -0.3159],\n         [ 1.0000,  0.6694, -0.1568,  1.7311, -0.6625, -0.4334],\n         [ 1.0000,  0.6694, -0.1568,  1.7311, -0.6500, -0.3768],\n         [ 1.0000,  0.6694, -0.1568,  1.7312, -0.6375, -0.3594],\n         [ 1.0000,  0.6694, -0.1568,  1.7312, -0.6250, -0.2985],\n         [ 1.0000,  0.6694, -0.1568,  1.7312, -0.6125, -0.2375],\n         [ 1.0000,  0.6694, -0.1568,  1.7312, -0.6000, -0.3072],\n         [ 1.0000,  0.6694, -0.1568,  1.7312, -0.5875, -0.4029],\n         [ 1.0000,  0.6694, -0.1568,  1.7312, -0.5750, -0.2811],\n         [ 1.0000,  0.6694, -0.1568,  1.7313, -0.5625, -0.1766],\n         [ 1.0000,  0.6694, -0.1568,  1.7313, -0.5500, -0.2027],\n         [ 1.0000,  0.6694, -0.1568,  1.7313, -0.5375,  0.1194],\n         [ 1.0000,  0.6694, -0.1568,  1.7313, -0.5250,  0.1020],\n         [ 1.0000,  0.6694, -0.1568,  1.7313, -0.5125,  0.2238],\n         [ 1.0000,  0.6694, -0.1568,  1.7314, -0.5000,  0.0410],\n         [ 1.0000,  0.6694, -0.1568,  1.7314, -0.4875,  0.4458],\n         [ 1.0000,  0.6694, -0.1568,  1.7314, -0.4750,  0.2673],\n         [ 1.0000,  0.6694, -0.1568,  1.7314, -0.4625,  0.5807],\n         [ 1.0000,  0.6694, -0.1568,  1.7314, -0.4500,  0.3283],\n         [ 1.0000,  0.6694, -0.1568,  1.7314, -0.4375,  0.4632],\n         [ 1.0000,  0.6694, -0.1568,  1.7315, -0.4250,  0.3283],\n         [ 1.0000,  0.6694, -0.1568,  1.7315, -0.4125,  0.7287],\n         [ 1.0000,  0.6694, -0.1568,  1.7315, -0.4000,  0.5416],\n         [ 1.0000,  0.6694, -0.1568,  1.7315, -0.3875,  0.3283],\n         [ 1.0000,  0.6694, -0.1568,  1.7315, -0.3750,  0.5720],\n         [ 1.0000,  0.6694, -0.1568,  1.7315, -0.3625,  0.6547],\n         [ 1.0000,  0.6694, -0.1568,  1.7316, -0.3500,  0.7069],\n         [ 1.0000,  0.6694, -0.1568,  1.7316, -0.3375,  0.8201],\n         [ 1.0000,  0.6694, -0.1568,  1.7316, -0.3250,  0.9812],\n         [ 1.0000,  0.6694, -0.1568,  1.7316, -0.3125,  0.7374],\n         [ 1.0000,  0.6694, -0.1568,  1.7316, -0.3000,  0.8941],\n         [ 1.0000,  0.6694, -0.1568,  1.7317, -0.2875,  1.1030],\n         [ 1.0000,  0.6694, -0.1568,  1.7317, -0.2750,  0.8985],\n         [ 1.0000,  0.6694, -0.1568,  1.7317, -0.2625,  0.9202],\n         [ 1.0000,  0.6694, -0.1568,  1.7317, -0.2500,  0.8506],\n         [ 1.0000,  0.6694, -0.1568,  1.7317, -0.2375,  0.9724],\n         [ 1.0000,  0.6694, -0.1568,  1.7317, -0.2250,  0.9028],\n         [ 1.0000,  0.6694, -0.1568,  1.7318, -0.2125,  0.9289],\n         [ 1.0000,  0.6694, -0.1568,  1.7318, -0.2000,  1.0247],\n         [ 1.0000,  0.6694, -0.1568,  1.7318, -0.1875,  1.0856],\n         [ 1.0000,  0.6694, -0.1568,  1.7318, -0.1750,  1.0987],\n         [ 1.0000,  0.6694, -0.1568,  1.7318, -0.1625,  1.1117],\n         [ 1.0000,  0.6694, -0.1568,  1.7318, -0.1500,  1.4208],\n         [ 1.0000,  0.6694, -0.1568,  1.7319, -0.1375,  1.1901],\n         [ 1.0000,  0.6694, -0.1568,  1.7319, -0.1250,  1.2945],\n         [ 1.0000,  0.6694, -0.1568,  1.7319, -0.1125,  1.3903],\n         [ 1.0000,  0.6694, -0.1568,  1.7319, -0.1000,  1.1901],\n         [ 1.0000,  0.6694, -0.1568,  1.7319, -0.0875,  0.9202],\n         [ 1.0000,  0.6694, -0.1568,  1.7320, -0.0750,  0.7418],\n         [ 1.0000,  0.6694, -0.1568,  1.7320, -0.0625,  0.7983],\n         [ 1.0000,  0.6694, -0.1568,  1.7320, -0.0500,  0.8593],\n         [ 1.0000,  0.6694, -0.1568,  1.7320, -0.0375,  1.0769],\n         [ 1.0000,  0.6694, -0.1568,  1.7320, -0.0250,  0.9463],\n         [ 1.0000,  0.6694, -0.1568,  1.7320, -0.0125,  0.9899]]],\n       device='cuda:0'), 'encoder_target': tensor([[1.7132, 1.5441, 1.5294, 1.8382, 1.5809, 2.0074, 1.6912, 1.7059, 1.9118,\n         1.9118, 1.9412, 2.9706, 3.5588, 3.8529, 3.9485, 3.7794, 4.2794, 4.0294,\n         4.2794, 3.9191, 4.0221, 4.0221, 4.0588, 4.3309, 4.0221, 4.2794, 4.4559,\n         4.2574, 4.3529, 4.3824, 4.4853, 4.5882, 4.4706, 4.3088, 4.5147, 4.6912,\n         4.6471, 5.1912, 5.1618, 5.3676, 5.0588, 5.7426, 5.4412, 5.9706, 5.5441,\n         5.7721, 5.5441, 6.2206, 5.9044, 5.5441, 5.9559, 6.0956, 6.1838, 6.3750,\n         6.6471, 6.2353, 6.5000, 6.8529, 6.5074, 6.5441, 6.4265, 6.6324, 6.5147,\n         6.5588, 6.7206, 6.8235, 6.8456, 6.8676, 7.3897, 7.0000, 7.1765, 7.3382,\n         7.0000, 6.5441, 6.2426, 6.3382, 6.4412, 6.8088, 6.5882, 6.6618]],\n       device='cuda:0'), 'encoder_lengths': tensor([80], device='cuda:0'), 'decoder_cat': tensor([], device='cuda:0', size=(1, 20, 0), dtype=torch.int64), 'decoder_cont': tensor([[[ 1.0000,  0.6694, -0.1568,  1.7321,  0.0000,  1.2379],\n         [ 1.0000,  0.6694, -0.1568,  1.7321,  0.0125,  0.9594],\n         [ 1.0000,  0.6694, -0.1568,  1.7321,  0.0250,  1.0247],\n         [ 1.0000,  0.6694, -0.1568,  1.7321,  0.0375,  1.0464],\n         [ 1.0000,  0.6694, -0.1568,  1.7321,  0.0500,  1.0987],\n         [ 1.0000,  0.6694, -0.1568,  1.7321,  0.0625,  1.2118],\n         [ 1.0000,  0.6694, -0.1568,  1.7322,  0.0750,  1.0595],\n         [ 1.0000,  0.6694, -0.1568,  1.7322,  0.0875,  1.2902],\n         [ 1.0000,  0.6694, -0.1568,  1.7322,  0.1000,  1.1161],\n         [ 1.0000,  0.6694, -0.1568,  1.7322,  0.1125,  1.2423],\n         [ 1.0000,  0.6694, -0.1568,  1.7322,  0.1250,  1.3337],\n         [ 1.0000,  0.6694, -0.1568,  1.7323,  0.1375,  1.2641],\n         [ 1.0000,  0.6694, -0.1568,  1.7323,  0.1500,  1.2597],\n         [ 1.0000,  0.6694, -0.1568,  1.7323,  0.1625,  1.3032],\n         [ 1.0000,  0.6694, -0.1568,  1.7323,  0.1750,  1.2205],\n         [ 1.0000,  0.6694, -0.1568,  1.7323,  0.1875, -1.4388],\n         [ 1.0000,  0.6694, -0.1568,  1.7323,  0.2000, -2.0220],\n         [ 1.0000,  0.6694, -0.1568,  1.7324,  0.2125, -1.9655],\n         [ 1.0000,  0.6694, -0.1568,  1.7324,  0.2250, -2.0830],\n         [ 1.0000,  0.6694, -0.1568,  1.7324,  0.2375, -1.9872]]],\n       device='cuda:0'), 'decoder_target': tensor([[7.0809, 6.6103, 6.7206, 6.7574, 6.8456, 7.0368, 6.7794, 7.1691, 6.8750,\n         7.0882, 7.2426, 7.1250, 7.1176, 7.1912, 7.0515, 2.5588, 1.5735, 1.6691,\n         1.4706, 1.6324]], device='cuda:0'), 'decoder_lengths': tensor([20], device='cuda:0'), 'decoder_time_idx': tensor([[196072, 196073, 196074, 196075, 196076, 196077, 196078, 196079, 196080,\n         196081, 196082, 196083, 196084, 196085, 196086, 196087, 196088, 196089,\n         196090, 196091]], device='cuda:0'), 'groups': tensor([[0]], device='cuda:0'), 'target_scale': tensor([[4.9895, 1.6894]], device='cuda:0')}, index=None, decoder_lengths=None, y=None)"
}