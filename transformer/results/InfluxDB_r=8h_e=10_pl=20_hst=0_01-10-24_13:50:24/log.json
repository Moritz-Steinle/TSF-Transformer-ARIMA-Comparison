{
    "label": "InfluxDB_r=8h_e=10_pl=20_hst=0",
    "error_metrics": "None",
    "runtimes": "Training: 19.36 seconds",
    "length_train_dataset": 91,
    "length_test_dataset": 1,
    "parameters": "Epochs: 10, hyperparameters: Hyperparamters(gradient_clip_val=0.09050490030726796, hidden_continuous_size=12, dropout=0.22288661702971777, attention_head_size=2, learning_rate=0.6336776189720053, accelerator='auto', hidden_size=None)",
    "prediction": "Prediction(output=Output(prediction=tensor([[[5.0375, 4.3726, 4.6820, 5.0023, 3.6656, 6.7369, 3.3185],\n         [5.0292, 4.3651, 4.6879, 4.9919, 3.6527, 6.7387, 3.2979],\n         [5.0441, 4.3522, 4.6949, 4.9671, 3.6507, 6.7449, 3.2922],\n         [5.0662, 4.3370, 4.6986, 4.9363, 3.6581, 6.7585, 3.2925],\n         [5.0885, 4.3209, 4.7002, 4.9037, 3.6712, 6.7773, 3.2956],\n         [5.1087, 4.3043, 4.7011, 4.8714, 3.6873, 6.7993, 3.3005],\n         [5.1264, 4.2877, 4.7019, 4.8403, 3.7047, 6.8228, 3.3066],\n         [5.1418, 4.2711, 4.7029, 4.8108, 3.7224, 6.8468, 3.3135],\n         [5.1555, 4.2549, 4.7041, 4.7829, 3.7399, 6.8707, 3.3211],\n         [5.1676, 4.2391, 4.7055, 4.7566, 3.7572, 6.8939, 3.3290],\n         [5.1787, 4.2239, 4.7071, 4.7316, 3.7740, 6.9164, 3.3371],\n         [5.1888, 4.2092, 4.7087, 4.7079, 3.7904, 6.9378, 3.3453],\n         [5.1982, 4.1953, 4.7103, 4.6853, 3.8064, 6.9583, 3.3535],\n         [5.3322, 3.1286, 5.6123, 5.5993, 4.1038, 6.3260, 3.7891],\n         [5.3255, 3.1740, 5.6433, 5.6206, 4.0680, 6.2307, 3.7763],\n         [5.3182, 3.2063, 5.6589, 5.6281, 4.0439, 6.1749, 3.7689],\n         [5.3153, 3.2276, 5.6643, 5.6229, 4.0341, 6.1444, 3.7634],\n         [5.3165, 3.2443, 5.6634, 5.6107, 4.0325, 6.1245, 3.7575],\n         [5.3202, 3.2594, 5.6593, 5.5951, 4.0353, 6.1085, 3.7511],\n         [5.3252, 3.2740, 5.6535, 5.5777, 4.0403, 6.0940, 3.7443]]],\n       device='cuda:0'), encoder_attention=tensor([[[[0.0176, 0.0177, 0.0178,  ..., 0.0036, 0.0034, 0.0033],\n          [0.0061, 0.0067, 0.0070,  ..., 0.0381, 0.0418, 0.0452],\n          [0.0479, 0.0430, 0.0401,  ..., 0.0145, 0.0191, 0.0265],\n          [0.0138, 0.0149, 0.0153,  ..., 0.0019, 0.0017, 0.0015]],\n\n         [[0.0176, 0.0176, 0.0178,  ..., 0.0036, 0.0034, 0.0033],\n          [0.0061, 0.0066, 0.0070,  ..., 0.0378, 0.0414, 0.0447],\n          [0.0463, 0.0417, 0.0388,  ..., 0.0147, 0.0194, 0.0270],\n          [0.0136, 0.0147, 0.0151,  ..., 0.0019, 0.0017, 0.0015]],\n\n         [[0.0174, 0.0175, 0.0177,  ..., 0.0036, 0.0034, 0.0033],\n          [0.0060, 0.0065, 0.0069,  ..., 0.0376, 0.0410, 0.0442],\n          [0.0451, 0.0406, 0.0378,  ..., 0.0147, 0.0194, 0.0270],\n          [0.0134, 0.0145, 0.0150,  ..., 0.0020, 0.0018, 0.0016]],\n\n         ...,\n\n         [[0.0079, 0.0072, 0.0070,  ..., 0.0142, 0.0155, 0.0168],\n          [0.0059, 0.0065, 0.0068,  ..., 0.0278, 0.0300, 0.0322],\n          [0.0359, 0.0314, 0.0288,  ..., 0.0096, 0.0140, 0.0218],\n          [0.0077, 0.0079, 0.0080,  ..., 0.0091, 0.0086, 0.0082]],\n\n         [[0.0078, 0.0071, 0.0069,  ..., 0.0140, 0.0153, 0.0166],\n          [0.0059, 0.0064, 0.0067,  ..., 0.0278, 0.0299, 0.0320],\n          [0.0351, 0.0307, 0.0281,  ..., 0.0091, 0.0133, 0.0207],\n          [0.0075, 0.0077, 0.0078,  ..., 0.0090, 0.0085, 0.0081]],\n\n         [[0.0076, 0.0069, 0.0067,  ..., 0.0138, 0.0151, 0.0164],\n          [0.0059, 0.0064, 0.0067,  ..., 0.0277, 0.0298, 0.0319],\n          [0.0343, 0.0300, 0.0274,  ..., 0.0087, 0.0126, 0.0197],\n          [0.0073, 0.0075, 0.0076,  ..., 0.0089, 0.0084, 0.0080]]]],\n       device='cuda:0'), decoder_attention=tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n\n         [[0.0117, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n          [0.0039, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n          [0.0259, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n          [0.0010, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n\n         [[0.0115, 0.0113, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n          [0.0038, 0.0038, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n          [0.0251, 0.0251, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n          [0.0010, 0.0010, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n\n         ...,\n\n         [[0.0178, 0.0177, 0.0179,  ..., 0.0000, 0.0000, 0.0000],\n          [0.0040, 0.0040, 0.0040,  ..., 0.0000, 0.0000, 0.0000],\n          [0.0194, 0.0195, 0.0197,  ..., 0.0000, 0.0000, 0.0000],\n          [0.0124, 0.0124, 0.0125,  ..., 0.0000, 0.0000, 0.0000]],\n\n         [[0.0175, 0.0175, 0.0176,  ..., 0.0205, 0.0000, 0.0000],\n          [0.0040, 0.0040, 0.0040,  ..., 0.0011, 0.0000, 0.0000],\n          [0.0189, 0.0190, 0.0192,  ..., 0.0307, 0.0000, 0.0000],\n          [0.0122, 0.0123, 0.0123,  ..., 0.0178, 0.0000, 0.0000]],\n\n         [[0.0172, 0.0172, 0.0174,  ..., 0.0201, 0.0201, 0.0000],\n          [0.0040, 0.0041, 0.0040,  ..., 0.0011, 0.0011, 0.0000],\n          [0.0184, 0.0185, 0.0187,  ..., 0.0300, 0.0294, 0.0000],\n          [0.0121, 0.0121, 0.0122,  ..., 0.0175, 0.0176, 0.0000]]]],\n       device='cuda:0'), static_variables=tensor([[[0.0908, 0.1033, 0.8059]]], device='cuda:0'), encoder_variables=tensor([[[[0.7887, 0.0746, 0.1367]],\n\n         [[0.7894, 0.0748, 0.1358]],\n\n         [[0.7881, 0.0743, 0.1376]],\n\n         [[0.7855, 0.0733, 0.1412]],\n\n         [[0.7823, 0.0721, 0.1455]],\n\n         [[0.7786, 0.0710, 0.1505]],\n\n         [[0.7769, 0.0705, 0.1526]],\n\n         [[0.7748, 0.0699, 0.1553]],\n\n         [[0.7713, 0.0691, 0.1597]],\n\n         [[0.7476, 0.0650, 0.1874]],\n\n         [[0.7184, 0.0620, 0.2195]],\n\n         [[0.7311, 0.0631, 0.2058]],\n\n         [[0.7411, 0.0642, 0.1947]],\n\n         [[0.7254, 0.0626, 0.2120]],\n\n         [[0.7208, 0.0622, 0.2170]],\n\n         [[0.7094, 0.0614, 0.2292]],\n\n         [[0.6711, 0.0594, 0.2695]],\n\n         [[0.6910, 0.0603, 0.2487]],\n\n         [[0.6796, 0.0597, 0.2607]],\n\n         [[0.6740, 0.0595, 0.2665]],\n\n         [[0.6587, 0.0589, 0.2824]],\n\n         [[0.6579, 0.0589, 0.2833]],\n\n         [[0.6422, 0.0584, 0.2994]],\n\n         [[0.6339, 0.0582, 0.3080]],\n\n         [[0.7952, 0.0779, 0.1270]],\n\n         [[0.7921, 0.0761, 0.1318]],\n\n         [[0.7895, 0.0749, 0.1355]],\n\n         [[0.7851, 0.0731, 0.1418]],\n\n         [[0.7817, 0.0719, 0.1463]],\n\n         [[0.7709, 0.0690, 0.1601]],\n\n         [[0.7704, 0.0689, 0.1608]],\n\n         [[0.7501, 0.0653, 0.1845]],\n\n         [[0.7338, 0.0634, 0.2028]],\n\n         [[0.7179, 0.0620, 0.2201]],\n\n         [[0.6484, 0.0586, 0.2930]],\n\n         [[0.6571, 0.0589, 0.2840]],\n\n         [[0.6197, 0.0579, 0.3224]],\n\n         [[0.6146, 0.0577, 0.3276]],\n\n         [[0.5667, 0.0570, 0.3763]],\n\n         [[0.5538, 0.0569, 0.3893]],\n\n         [[0.5146, 0.0566, 0.4287]],\n\n         [[0.4318, 0.0566, 0.5115]],\n\n         [[0.8014, 0.0829, 0.1157]],\n\n         [[0.8022, 0.0838, 0.1140]],\n\n         [[0.7995, 0.0811, 0.1194]],\n\n         [[0.8014, 0.0830, 0.1156]],\n\n         [[0.7903, 0.0753, 0.1344]],\n\n         [[0.7926, 0.0764, 0.1309]],\n\n         [[0.7910, 0.0756, 0.1335]],\n\n         [[0.7670, 0.0682, 0.1648]],\n\n         [[0.7800, 0.0714, 0.1486]],\n\n         [[0.7378, 0.0638, 0.1984]],\n\n         [[0.7525, 0.0657, 0.1818]],\n\n         [[0.6700, 0.0593, 0.2706]],\n\n         [[0.7134, 0.0617, 0.2250]],\n\n         [[0.6985, 0.0607, 0.2409]],\n\n         [[0.6614, 0.0590, 0.2796]],\n\n         [[0.6311, 0.0581, 0.3108]],\n\n         [[0.5488, 0.0568, 0.3943]],\n\n         [[0.4859, 0.0565, 0.4575]],\n\n         [[0.4817, 0.0565, 0.4617]],\n\n         [[0.3978, 0.0568, 0.5454]],\n\n         [[0.3733, 0.0571, 0.5696]],\n\n         [[0.4141, 0.0567, 0.5292]],\n\n         [[0.3487, 0.0574, 0.5939]],\n\n         [[0.3212, 0.0579, 0.6209]],\n\n         [[0.2996, 0.0584, 0.6420]],\n\n         [[0.2528, 0.0601, 0.6871]],\n\n         [[0.2219, 0.0619, 0.7163]],\n\n         [[0.1718, 0.0671, 0.7611]],\n\n         [[0.1676, 0.0677, 0.7647]],\n\n         [[0.1492, 0.0713, 0.7795]],\n\n         [[0.1450, 0.0723, 0.7827]],\n\n         [[0.1358, 0.0749, 0.7894]],\n\n         [[0.1283, 0.0774, 0.7943]],\n\n         [[0.1210, 0.0804, 0.7986]],\n\n         [[0.1146, 0.0835, 0.8018]],\n\n         [[0.1098, 0.0863, 0.8038]],\n\n         [[0.1050, 0.0896, 0.8054]],\n\n         [[0.1007, 0.0930, 0.8063]]]], device='cuda:0'), decoder_variables=tensor([[[[0.8808, 0.1192]],\n\n         [[0.8808, 0.1192]],\n\n         [[0.8808, 0.1192]],\n\n         [[0.8808, 0.1192]],\n\n         [[0.8808, 0.1192]],\n\n         [[0.8808, 0.1192]],\n\n         [[0.8808, 0.1192]],\n\n         [[0.8808, 0.1192]],\n\n         [[0.8808, 0.1192]],\n\n         [[0.8808, 0.1192]],\n\n         [[0.8808, 0.1192]],\n\n         [[0.8808, 0.1192]],\n\n         [[0.8808, 0.1192]],\n\n         [[0.1192, 0.8808]],\n\n         [[0.1192, 0.8808]],\n\n         [[0.1192, 0.8808]],\n\n         [[0.1192, 0.8808]],\n\n         [[0.1192, 0.8808]],\n\n         [[0.1192, 0.8808]],\n\n         [[0.1192, 0.8808]]]], device='cuda:0'), decoder_lengths=tensor([20], device='cuda:0'), encoder_lengths=tensor([80], device='cuda:0')), x={'encoder_cat': tensor([], device='cuda:0', size=(1, 80, 0), dtype=torch.int64), 'encoder_cont': tensor([[[ 1.0000, -0.0412,  0.0136, -1.4703, -1.0000, -1.7691],\n         [ 1.0000, -0.0412,  0.0136, -1.4300, -0.9875, -1.7856],\n         [ 1.0000, -0.0412,  0.0136, -1.3898, -0.9750, -1.6910],\n         [ 1.0000, -0.0412,  0.0136, -1.3495, -0.9625, -1.5388],\n         [ 1.0000, -0.0412,  0.0136, -1.3092, -0.9500, -1.3742],\n         [ 1.0000, -0.0412,  0.0136, -1.2689, -0.9375, -1.2056],\n         [ 1.0000, -0.0412,  0.0136, -1.2286, -0.9250, -1.1316],\n         [ 1.0000, -0.0412,  0.0136, -1.1883, -0.9125, -1.0452],\n         [ 1.0000, -0.0412,  0.0136, -1.1481, -0.9000, -0.9218],\n         [ 1.0000, -0.0412,  0.0136, -1.1078, -0.8875, -0.3254],\n         [ 1.0000, -0.0412,  0.0136, -1.0675, -0.8750,  0.1970],\n         [ 1.0000, -0.0412,  0.0136, -1.0272, -0.8625, -0.0210],\n         [ 1.0000, -0.0412,  0.0136, -0.9869, -0.8500, -0.2061],\n         [ 1.0000, -0.0412,  0.0136, -0.9466, -0.8375,  0.0571],\n         [ 1.0000, -0.0412,  0.0136, -0.9064, -0.8250,  0.1188],\n         [ 1.0000, -0.0412,  0.0136, -0.8661, -0.8125,  0.2710],\n         [ 1.0000, -0.0412,  0.0136, -0.8258, -0.8000,  0.7317],\n         [ 1.0000, -0.0412,  0.0136, -0.7855, -0.7875,  0.4767],\n         [ 1.0000, -0.0412,  0.0136, -0.7452, -0.7750,  0.5918],\n         [ 1.0000, -0.0412,  0.0136, -0.7050, -0.7625,  0.6330],\n         [ 1.0000, -0.0412,  0.0136, -0.6647, -0.7500,  0.7728],\n         [ 1.0000, -0.0412,  0.0136, -0.6244, -0.7375,  0.7564],\n         [ 1.0000, -0.0412,  0.0136, -0.5841, -0.7250,  0.8839],\n         [ 1.0000, -0.0412,  0.0136, -0.5438, -0.7125,  0.9332],\n         [ 1.0000, -0.0412,  0.0136, -0.5035, -0.7000, -1.5676],\n         [ 1.0000, -0.0412,  0.0136, -0.4633, -0.6875, -1.4030],\n         [ 1.0000, -0.0412,  0.0136, -0.4230, -0.6750, -1.2838],\n         [ 1.0000, -0.0412,  0.0136, -0.3827, -0.6625, -1.1192],\n         [ 1.0000, -0.0412,  0.0136, -0.3424, -0.6500, -1.0123],\n         [ 1.0000, -0.0412,  0.0136, -0.3021, -0.6375, -0.7573],\n         [ 1.0000, -0.0412,  0.0136, -0.2618, -0.6250, -0.7408],\n         [ 1.0000, -0.0412,  0.0136, -0.2216, -0.6125, -0.4159],\n         [ 1.0000, -0.0412,  0.0136, -0.1813, -0.6000, -0.2185],\n         [ 1.0000, -0.0412,  0.0136, -0.1410, -0.5875, -0.0622],\n         [ 1.0000, -0.0412,  0.0136, -0.1007, -0.5750,  0.4931],\n         [ 1.0000, -0.0412,  0.0136, -0.0604, -0.5625,  0.4026],\n         [ 1.0000, -0.0412,  0.0136, -0.0201, -0.5500,  0.6330],\n         [ 1.0000, -0.0412,  0.0136,  0.0201, -0.5375,  0.6330],\n         [ 1.0000, -0.0412,  0.0136,  0.0604, -0.5250,  0.9003],\n         [ 1.0000, -0.0412,  0.0136,  0.1007, -0.5125,  0.9373],\n         [ 1.0000, -0.0412,  0.0136,  0.1410, -0.5000,  1.1348],\n         [ 1.0000, -0.0412,  0.0136,  0.1813, -0.4875,  1.6530],\n         [ 1.0000, -0.0412,  0.0136,  0.2216, -0.4750, -1.3948],\n         [ 1.0000, -0.0412,  0.0136,  0.2618, -0.4625, -1.4071],\n         [ 1.0000, -0.0412,  0.0136,  0.3021, -0.4500, -1.2591],\n         [ 1.0000, -0.0412,  0.0136,  0.3424, -0.4375, -1.3125],\n         [ 1.0000, -0.0412,  0.0136,  0.3827, -0.4250, -0.9712],\n         [ 1.0000, -0.0412,  0.0136,  0.4230, -0.4125, -1.0041],\n         [ 1.0000, -0.0412,  0.0136,  0.4633, -0.4000, -0.9547],\n         [ 1.0000, -0.0412,  0.0136,  0.5035, -0.3875, -0.6339],\n         [ 1.0000, -0.0412,  0.0136,  0.5438, -0.3750, -0.7696],\n         [ 1.0000, -0.0412,  0.0136,  0.5841, -0.3625, -0.4200],\n         [ 1.0000, -0.0412,  0.0136,  0.6244, -0.3500, -0.5228],\n         [ 1.0000, -0.0412,  0.0136,  0.6647, -0.3375, -0.1280],\n         [ 1.0000, -0.0412,  0.0136,  0.7050, -0.3250, -0.3295],\n         [ 1.0000, -0.0412,  0.0136,  0.7452, -0.3125, -0.2843],\n         [ 1.0000, -0.0412,  0.0136,  0.7855, -0.3000, -0.1732],\n         [ 1.0000, -0.0412,  0.0136,  0.8258, -0.2875, -0.1074],\n         [ 1.0000, -0.0412,  0.0136,  0.8661, -0.2750,  0.0900],\n         [ 1.0000, -0.0412,  0.0136,  0.9064, -0.2625,  0.2216],\n         [ 1.0000, -0.0412,  0.0136,  0.9466, -0.2500,  0.1764],\n         [ 1.0000, -0.0412,  0.0136,  0.9869, -0.2375,  0.3779],\n         [ 1.0000, -0.0412,  0.0136,  1.0272, -0.2250,  0.3903],\n         [ 1.0000, -0.0412,  0.0136,  1.0675, -0.2125,  0.1764],\n         [ 1.0000, -0.0412,  0.0136,  1.1078, -0.2000,  0.3121],\n         [ 1.0000, -0.0412,  0.0136,  1.1481, -0.1875,  0.3286],\n         [ 1.0000, -0.0412,  0.0136,  1.1883, -0.1750,  0.3204],\n         [ 1.0000, -0.0412,  0.0136,  1.2286, -0.1625,  0.4643],\n         [ 1.0000, -0.0412,  0.0136,  1.2689, -0.1500,  0.5713],\n         [ 1.0000, -0.0412,  0.0136,  1.3092, -0.1375,  1.1594],\n         [ 1.0000, -0.0412,  0.0136,  1.3495, -0.1250,  1.0196],\n         [ 1.0000, -0.0412,  0.0136,  1.3898, -0.1125,  1.3363],\n         [ 1.0000, -0.0412,  0.0136,  1.4300, -0.1000,  1.1882],\n         [ 1.0000, -0.0412,  0.0136,  1.4703, -0.0875,  1.2952],\n         [ 1.0000, -0.0412,  0.0136,  1.5106, -0.0750,  1.3651],\n         [ 1.0000, -0.0412,  0.0136,  1.5509, -0.0625,  1.5214],\n         [ 1.0000, -0.0412,  0.0136,  1.5912, -0.0500,  1.7024],\n         [ 1.0000, -0.0412,  0.0136,  1.6315, -0.0375,  1.7846],\n         [ 1.0000, -0.0412,  0.0136,  1.6717, -0.0250,  1.9985],\n         [ 1.0000, -0.0412,  0.0136,  1.7120, -0.0125,  2.2576]]],\n       device='cuda:0'), 'encoder_target': tensor([[1.0327, 1.0000, 1.1882, 1.4909, 1.8182, 2.1536, 2.3009, 2.4727, 2.7182,\n         3.9045, 4.9436, 4.5100, 4.1418, 4.6655, 4.7882, 5.0909, 6.0073, 5.5000,\n         5.7291, 5.8109, 6.0891, 6.0564, 6.3100, 6.4082, 1.4336, 1.7609, 1.9982,\n         2.3255, 2.5382, 3.0455, 3.0782, 3.7245, 4.1173, 4.4282, 5.5327, 5.3527,\n         5.8109, 5.8109, 6.3427, 6.4164, 6.8091, 7.8400, 1.7773, 1.7527, 2.0473,\n         1.9409, 2.6200, 2.5545, 2.6527, 3.2909, 3.0209, 3.7164, 3.5118, 4.2973,\n         3.8964, 3.9864, 4.2073, 4.3382, 4.7309, 4.9927, 4.9027, 5.3036, 5.3282,\n         4.9027, 5.1727, 5.2055, 5.1891, 5.4755, 5.6882, 6.8582, 6.5800, 7.2100,\n         6.9155, 7.1282, 7.2673, 7.5782, 7.9382, 8.1018, 8.5273, 9.0427]],\n       device='cuda:0'), 'encoder_lengths': tensor([80], device='cuda:0'), 'decoder_cat': tensor([], device='cuda:0', size=(1, 20, 0), dtype=torch.int64), 'decoder_cont': tensor([[[ 1.0000, -0.0412,  0.0136,  1.7523,  0.0000,  2.3276],\n         [ 1.0000, -0.0412,  0.0136,  1.7926,  0.0125,  2.5456],\n         [ 1.0000, -0.0412,  0.0136,  1.8329,  0.0250,  2.7389],\n         [ 1.0000, -0.0412,  0.0136,  1.8732,  0.0375,  0.3533],\n         [ 1.0000, -0.0412,  0.0136,  1.9134,  0.0500, -0.0210],\n         [ 1.0000, -0.0412,  0.0136,  1.9537,  0.0625,  0.0037],\n         [ 1.0000, -0.0412,  0.0136,  1.9940,  0.0750,  0.2463],\n         [ 1.0000, -0.0412,  0.0136,  2.0343,  0.0875, -0.4735],\n         [ 1.0000, -0.0412,  0.0136,  2.0746,  0.1000, -0.2390],\n         [ 1.0000, -0.0412,  0.0136,  2.1149,  0.1125, -0.0416],\n         [ 1.0000, -0.0412,  0.0136,  2.1551,  0.1250, -0.0046],\n         [ 1.0000, -0.0412,  0.0136,  2.1954,  0.1375,  0.1065],\n         [ 1.0000, -0.0412,  0.0136,  2.2357,  0.1500,  0.1641],\n         [ 1.0000, -0.0412,  0.0136,  2.2760,  0.1625,  0.1970],\n         [ 1.0000, -0.0412,  0.0136,  2.3163,  0.1750,  0.3738],\n         [ 1.0000, -0.0412,  0.0136,  2.3566,  0.1875,  0.4479],\n         [ 1.0000, -0.0412,  0.0136,  2.3968,  0.2000,  0.5713],\n         [ 1.0000, -0.0412,  0.0136,  2.4371,  0.2125,  0.6330],\n         [ 1.0000, -0.0412,  0.0136,  2.4774,  0.2250,  0.7317],\n         [ 1.0000, -0.0412,  0.0136,  2.5177,  0.2375,  0.8222]]],\n       device='cuda:0'), 'decoder_target': tensor([[ 9.1818,  9.6155, 10.0000,  5.2545,  4.5100,  4.5591,  5.0418,  3.6100,\n          4.0764,  4.4691,  4.5427,  4.7636,  4.8782,  4.9436,  5.2955,  5.4427,\n          5.6882,  5.8109,  6.0073,  6.1873]], device='cuda:0'), 'decoder_lengths': tensor([20], device='cuda:0'), 'decoder_time_idx': tensor([[ 86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99,\n         100, 101, 102, 103, 104, 105]], device='cuda:0'), 'groups': tensor([[0]], device='cuda:0'), 'target_scale': tensor([[4.5518, 1.9892]], device='cuda:0')}, index=None, decoder_lengths=None, y=None)"
}