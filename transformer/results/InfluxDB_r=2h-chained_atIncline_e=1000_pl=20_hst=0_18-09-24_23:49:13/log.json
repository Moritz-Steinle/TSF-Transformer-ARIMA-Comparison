{"label":"InfluxDB_r=2h-chained_atIncline_e=1000_pl=20_hst=0","mean_squared_error":-1,"runtimes":"Training: 72.65 seconds","length_train_dataset":5396,"length_test_dataset":1,"parameters":"Epochs: 1000, hyperparameters: Hyperparamters(gradient_clip_val=6.9953515571, hidden_continuous_size=40, dropout=0.1558743686, attention_head_size=3, learning_rate=0.0039810717, accelerator='auto', hidden_size=70)","prediction":"Prediction(output=Output(prediction=tensor([[[1.1780, 2.3331, 4.5219, 5.0638, 6.6613, 7.6687, 7.9402],\n         [1.1499, 2.3552, 4.4626, 5.0365, 6.6443, 7.6484, 7.9651],\n         [1.1135, 2.4384, 4.3796, 4.9734, 6.5507, 7.6040, 7.9480],\n         [1.0840, 2.5433, 4.2886, 4.9125, 6.4297, 7.5434, 7.9086],\n         [1.0656, 2.6387, 4.2043, 4.8629, 6.3168, 7.4826, 7.8638],\n         [1.0520, 2.7176, 4.1309, 4.8158, 6.2198, 7.4272, 7.8198],\n         [1.0410, 2.7804, 4.0682, 4.7670, 6.1386, 7.3805, 7.7793],\n         [1.0329, 2.8293, 4.0150, 4.7173, 6.0715, 7.3450, 7.7437],\n         [1.0275, 2.8669, 3.9704, 4.6691, 6.0161, 7.3214, 7.7134],\n         [1.0239, 2.8955, 3.9335, 4.6243, 5.9704, 7.3082, 7.6879],\n         [1.0213, 2.9176, 3.9035, 4.5842, 5.9324, 7.3025, 7.6666],\n         [1.0191, 2.9349, 3.8791, 4.5493, 5.9008, 7.3017, 7.6491],\n         [1.0170, 2.9486, 3.8594, 4.5197, 5.8745, 7.3037, 7.6349],\n         [1.0151, 2.9597, 3.8433, 4.4949, 5.8526, 7.3068, 7.6233],\n         [1.0134, 2.9688, 3.8301, 4.4744, 5.8346, 7.3103, 7.6141],\n         [1.0119, 2.9762, 3.8193, 4.4574, 5.8198, 7.3137, 7.6069],\n         [1.0106, 2.9823, 3.8103, 4.4434, 5.8078, 7.3169, 7.6012],\n         [1.0097, 2.9872, 3.8028, 4.4318, 5.7981, 7.3196, 7.5968],\n         [1.0090, 2.9912, 3.7966, 4.4222, 5.7903, 7.3220, 7.5934],\n         [1.0085, 2.9943, 3.7913, 4.4141, 5.7841, 7.3241, 7.5909]]],\n       device='cuda:0'), encoder_attention=tensor([[[[0.0119, 0.0120, 0.0121,  ..., 0.0123, 0.0123, 0.0123],\n          [0.0125, 0.0122, 0.0116,  ..., 0.0128, 0.0124, 0.0122],\n          [0.0101, 0.0107, 0.0110,  ..., 0.0137, 0.0137, 0.0138],\n          [0.0125, 0.0124, 0.0127,  ..., 0.0105, 0.0106, 0.0106]],\n\n         [[0.0117, 0.0117, 0.0119,  ..., 0.0121, 0.0121, 0.0120],\n          [0.0124, 0.0122, 0.0116,  ..., 0.0127, 0.0123, 0.0121],\n          [0.0100, 0.0105, 0.0108,  ..., 0.0135, 0.0135, 0.0136],\n          [0.0123, 0.0121, 0.0126,  ..., 0.0102, 0.0104, 0.0104]],\n\n         [[0.0114, 0.0115, 0.0117,  ..., 0.0119, 0.0119, 0.0118],\n          [0.0125, 0.0123, 0.0116,  ..., 0.0126, 0.0123, 0.0121],\n          [0.0097, 0.0102, 0.0105,  ..., 0.0133, 0.0133, 0.0134],\n          [0.0121, 0.0119, 0.0124,  ..., 0.0100, 0.0101, 0.0101]],\n\n         ...,\n\n         [[0.0090, 0.0092, 0.0095,  ..., 0.0096, 0.0096, 0.0096],\n          [0.0122, 0.0117, 0.0110,  ..., 0.0115, 0.0112, 0.0110],\n          [0.0070, 0.0076, 0.0080,  ..., 0.0108, 0.0108, 0.0108],\n          [0.0094, 0.0094, 0.0098,  ..., 0.0079, 0.0080, 0.0080]],\n\n         [[0.0089, 0.0091, 0.0094,  ..., 0.0095, 0.0095, 0.0095],\n          [0.0121, 0.0116, 0.0110,  ..., 0.0114, 0.0111, 0.0109],\n          [0.0069, 0.0075, 0.0079,  ..., 0.0106, 0.0106, 0.0107],\n          [0.0093, 0.0092, 0.0097,  ..., 0.0078, 0.0079, 0.0079]],\n\n         [[0.0088, 0.0090, 0.0093,  ..., 0.0094, 0.0094, 0.0094],\n          [0.0120, 0.0116, 0.0109,  ..., 0.0113, 0.0110, 0.0108],\n          [0.0068, 0.0074, 0.0078,  ..., 0.0105, 0.0105, 0.0106],\n          [0.0092, 0.0091, 0.0096,  ..., 0.0077, 0.0078, 0.0078]]]],\n       device='cuda:0'), decoder_attention=tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n\n         [[0.0182, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n          [0.0071, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n          [0.0174, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n          [0.0144, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n\n         [[0.0178, 0.0175, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n          [0.0071, 0.0070, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n          [0.0177, 0.0173, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n          [0.0142, 0.0139, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n\n         ...,\n\n         [[0.0144, 0.0141, 0.0137,  ..., 0.0000, 0.0000, 0.0000],\n          [0.0068, 0.0068, 0.0066,  ..., 0.0000, 0.0000, 0.0000],\n          [0.0184, 0.0175, 0.0163,  ..., 0.0000, 0.0000, 0.0000],\n          [0.0116, 0.0112, 0.0112,  ..., 0.0000, 0.0000, 0.0000]],\n\n         [[0.0142, 0.0139, 0.0136,  ..., 0.0117, 0.0000, 0.0000],\n          [0.0068, 0.0067, 0.0066,  ..., 0.0068, 0.0000, 0.0000],\n          [0.0182, 0.0173, 0.0161,  ..., 0.0112, 0.0000, 0.0000],\n          [0.0115, 0.0111, 0.0110,  ..., 0.0133, 0.0000, 0.0000]],\n\n         [[0.0140, 0.0138, 0.0134,  ..., 0.0116, 0.0116, 0.0000],\n          [0.0067, 0.0067, 0.0065,  ..., 0.0068, 0.0068, 0.0000],\n          [0.0180, 0.0172, 0.0159,  ..., 0.0110, 0.0110, 0.0000],\n          [0.0113, 0.0109, 0.0109,  ..., 0.0131, 0.0131, 0.0000]]]],\n       device='cuda:0'), static_variables=tensor([[[0.0584, 0.4923, 0.4492]]], device='cuda:0'), encoder_variables=tensor([[[[0.3879, 0.0424, 0.5697]],\n\n         [[0.3839, 0.0424, 0.5737]],\n\n         [[0.3949, 0.0424, 0.5627]],\n\n         [[0.3957, 0.0424, 0.5619]],\n\n         [[0.3969, 0.0424, 0.5607]],\n\n         [[0.3998, 0.0425, 0.5577]],\n\n         [[0.4177, 0.0426, 0.5397]],\n\n         [[0.3912, 0.0424, 0.5664]],\n\n         [[0.3996, 0.0425, 0.5579]],\n\n         [[0.4081, 0.0425, 0.5494]],\n\n         [[0.3983, 0.0424, 0.5592]],\n\n         [[0.4087, 0.0425, 0.5488]],\n\n         [[0.4050, 0.0425, 0.5525]],\n\n         [[0.4072, 0.0425, 0.5503]],\n\n         [[0.4104, 0.0425, 0.5471]],\n\n         [[0.4107, 0.0425, 0.5468]],\n\n         [[0.4115, 0.0425, 0.5460]],\n\n         [[0.4156, 0.0426, 0.5419]],\n\n         [[0.4142, 0.0426, 0.5433]],\n\n         [[0.4142, 0.0426, 0.5433]],\n\n         [[0.4165, 0.0426, 0.5409]],\n\n         [[0.4160, 0.0426, 0.5415]],\n\n         [[0.4152, 0.0426, 0.5423]],\n\n         [[0.4187, 0.0426, 0.5387]],\n\n         [[0.4167, 0.0426, 0.5407]],\n\n         [[0.4190, 0.0426, 0.5385]],\n\n         [[0.4237, 0.0426, 0.5337]],\n\n         [[0.4221, 0.0426, 0.5353]],\n\n         [[0.4217, 0.0426, 0.5357]],\n\n         [[0.4282, 0.0427, 0.5291]],\n\n         [[0.4339, 0.0427, 0.5234]],\n\n         [[0.4275, 0.0427, 0.5299]],\n\n         [[0.4240, 0.0426, 0.5334]],\n\n         [[0.4259, 0.0426, 0.5315]],\n\n         [[0.4426, 0.0428, 0.5146]],\n\n         [[0.4401, 0.0428, 0.5171]],\n\n         [[0.4301, 0.0427, 0.5272]],\n\n         [[0.4292, 0.0427, 0.5282]],\n\n         [[0.4354, 0.0427, 0.5219]],\n\n         [[0.4345, 0.0427, 0.5228]],\n\n         [[0.4519, 0.0429, 0.5053]],\n\n         [[0.4383, 0.0427, 0.5189]],\n\n         [[0.4577, 0.0429, 0.4993]],\n\n         [[0.4427, 0.0428, 0.5145]],\n\n         [[0.4481, 0.0428, 0.5090]],\n\n         [[0.4517, 0.0429, 0.5054]],\n\n         [[0.4500, 0.0429, 0.5072]],\n\n         [[0.4520, 0.0429, 0.5051]],\n\n         [[0.1271, 0.0504, 0.8226]],\n\n         [[0.1257, 0.0506, 0.8237]],\n\n         [[0.1294, 0.0500, 0.8207]],\n\n         [[0.1246, 0.0508, 0.8246]],\n\n         [[0.1238, 0.0509, 0.8253]],\n\n         [[0.1313, 0.0497, 0.8191]],\n\n         [[0.1239, 0.0509, 0.8251]],\n\n         [[0.1355, 0.0490, 0.8155]],\n\n         [[0.1256, 0.0506, 0.8238]],\n\n         [[0.1255, 0.0506, 0.8239]],\n\n         [[0.1308, 0.0497, 0.8195]],\n\n         [[0.1303, 0.0498, 0.8199]],\n\n         [[0.1306, 0.0498, 0.8196]],\n\n         [[0.1777, 0.0451, 0.7772]],\n\n         [[0.2180, 0.0434, 0.7386]],\n\n         [[0.2401, 0.0429, 0.7170]],\n\n         [[0.2468, 0.0428, 0.7104]],\n\n         [[0.2327, 0.0431, 0.7242]],\n\n         [[0.2714, 0.0425, 0.6861]],\n\n         [[0.2509, 0.0427, 0.7064]],\n\n         [[0.2698, 0.0425, 0.6877]],\n\n         [[0.2406, 0.0429, 0.7165]],\n\n         [[0.2479, 0.0428, 0.7093]],\n\n         [[0.2472, 0.0428, 0.7101]],\n\n         [[0.2493, 0.0427, 0.7080]],\n\n         [[0.2698, 0.0425, 0.6877]],\n\n         [[0.2448, 0.0428, 0.7124]],\n\n         [[0.2642, 0.0425, 0.6933]],\n\n         [[0.2771, 0.0424, 0.6805]],\n\n         [[0.2608, 0.0426, 0.6966]],\n\n         [[0.2675, 0.0425, 0.6900]],\n\n         [[0.2690, 0.0425, 0.6886]]]], device='cuda:0'), decoder_variables=tensor([[[[0.8644, 0.1356]],\n\n         [[0.8644, 0.1356]],\n\n         [[0.8644, 0.1356]],\n\n         [[0.8644, 0.1356]],\n\n         [[0.8644, 0.1356]],\n\n         [[0.8644, 0.1356]],\n\n         [[0.8644, 0.1356]],\n\n         [[0.8644, 0.1356]],\n\n         [[0.8644, 0.1356]],\n\n         [[0.8644, 0.1356]],\n\n         [[0.8644, 0.1356]],\n\n         [[0.8644, 0.1356]],\n\n         [[0.8644, 0.1356]],\n\n         [[0.8644, 0.1356]],\n\n         [[0.8644, 0.1356]],\n\n         [[0.8644, 0.1356]],\n\n         [[0.8644, 0.1356]],\n\n         [[0.8644, 0.1356]],\n\n         [[0.8644, 0.1356]],\n\n         [[0.8644, 0.1356]]]], device='cuda:0'), decoder_lengths=tensor([20], device='cuda:0'), encoder_lengths=tensor([80], device='cuda:0')), x={'encoder_cat': tensor([], device='cuda:0', size=(1, 80, 0), dtype=torch.int64), 'encoder_cont': tensor([[[ 1.0000,  0.7379, -0.0098,  1.6808, -1.0000,  0.0962],\n         [ 1.0000,  0.7379, -0.0098,  1.6815, -0.9875,  0.0641],\n         [ 1.0000,  0.7379, -0.0098,  1.6821, -0.9750,  0.1805],\n         [ 1.0000,  0.7379, -0.0098,  1.6828, -0.9625,  0.1966],\n         [ 1.0000,  0.7379, -0.0098,  1.6834, -0.9500,  0.2166],\n         [ 1.0000,  0.7379, -0.0098,  1.6841, -0.9375,  0.2568],\n         [ 1.0000,  0.7379, -0.0098,  1.6847, -0.9250,  0.4976],\n         [ 1.0000,  0.7379, -0.0098,  1.6853, -0.9125,  0.1765],\n         [ 1.0000,  0.7379, -0.0098,  1.6860, -0.9000,  0.2768],\n         [ 1.0000,  0.7379, -0.0098,  1.6866, -0.8875,  0.3892],\n         [ 1.0000,  0.7379, -0.0098,  1.6873, -0.8750,  0.2768],\n         [ 1.0000,  0.7379, -0.0098,  1.6879, -0.8625,  0.4133],\n         [ 1.0000,  0.7379, -0.0098,  1.6886, -0.8500,  0.3731],\n         [ 1.0000,  0.7379, -0.0098,  1.6892, -0.8375,  0.4093],\n         [ 1.0000,  0.7379, -0.0098,  1.6899, -0.8250,  0.4614],\n         [ 1.0000,  0.7379, -0.0098,  1.6905, -0.8125,  0.4735],\n         [ 1.0000,  0.7379, -0.0098,  1.6911, -0.8000,  0.4935],\n         [ 1.0000,  0.7379, -0.0098,  1.6918, -0.7875,  0.5618],\n         [ 1.0000,  0.7379, -0.0098,  1.6924, -0.7750,  0.5497],\n         [ 1.0000,  0.7379, -0.0098,  1.6931, -0.7625,  0.5578],\n         [ 1.0000,  0.7379, -0.0098,  1.6937, -0.7500,  0.6019],\n         [ 1.0000,  0.7379, -0.0098,  1.6944, -0.7375,  0.6019],\n         [ 1.0000,  0.7379, -0.0098,  1.6950, -0.7250,  0.5979],\n         [ 1.0000,  0.7379, -0.0098,  1.6957, -0.7125,  0.6621],\n         [ 1.0000,  0.7379, -0.0098,  1.6963, -0.7000,  0.6380],\n         [ 1.0000,  0.7379, -0.0098,  1.6969, -0.6875,  0.6822],\n         [ 1.0000,  0.7379, -0.0098,  1.6976, -0.6750,  0.7705],\n         [ 1.0000,  0.7379, -0.0098,  1.6982, -0.6625,  0.7504],\n         [ 1.0000,  0.7379, -0.0098,  1.6989, -0.6500,  0.7504],\n         [ 1.0000,  0.7379, -0.0098,  1.6995, -0.6375,  0.8748],\n         [ 1.0000,  0.7379, -0.0098,  1.7002, -0.6250,  0.9952],\n         [ 1.0000,  0.7379, -0.0098,  1.7008, -0.6125,  0.8748],\n         [ 1.0000,  0.7379, -0.0098,  1.7014, -0.6000,  0.8186],\n         [ 1.0000,  0.7379, -0.0098,  1.7021, -0.5875,  0.8588],\n         [ 1.0000,  0.7379, -0.0098,  1.7027, -0.5750,  1.1718],\n         [ 1.0000,  0.7379, -0.0098,  1.7034, -0.5625,  1.1317],\n         [ 1.0000,  0.7379, -0.0098,  1.7040, -0.5500,  0.9551],\n         [ 1.0000,  0.7379, -0.0098,  1.7047, -0.5375,  0.9430],\n         [ 1.0000,  0.7379, -0.0098,  1.7053, -0.5250,  1.0594],\n         [ 1.0000,  0.7379, -0.0098,  1.7060, -0.5125,  1.0474],\n         [ 1.0000,  0.7379, -0.0098,  1.7066, -0.5000,  1.3043],\n         [ 1.0000,  0.7379, -0.0098,  1.7072, -0.4875,  1.1116],\n         [ 1.0000,  0.7379, -0.0098,  1.7079, -0.4750,  1.3765],\n         [ 1.0000,  0.7379, -0.0098,  1.7085, -0.4625,  1.1758],\n         [ 1.0000,  0.7379, -0.0098,  1.7092, -0.4500,  1.2481],\n         [ 1.0000,  0.7379, -0.0098,  1.7098, -0.4375,  1.2922],\n         [ 1.0000,  0.7379, -0.0098,  1.7105, -0.4250,  1.2681],\n         [ 1.0000,  0.7379, -0.0098,  1.7111, -0.4125,  1.2922],\n         [ 1.0000,  0.7379, -0.0098,  1.7118, -0.4000, -1.8864],\n         [ 1.0000,  0.7379, -0.0098,  1.7124, -0.3875, -1.9065],\n         [ 1.0000,  0.7379, -0.0098,  1.7130, -0.3750, -1.8142],\n         [ 1.0000,  0.7379, -0.0098,  1.7137, -0.3625, -1.9065],\n         [ 1.0000,  0.7379, -0.0098,  1.7143, -0.3500, -1.9145],\n         [ 1.0000,  0.7379, -0.0098,  1.7150, -0.3375, -1.7459],\n         [ 1.0000,  0.7379, -0.0098,  1.7156, -0.3250, -1.8864],\n         [ 1.0000,  0.7379, -0.0098,  1.7163, -0.3125, -1.6536],\n         [ 1.0000,  0.7379, -0.0098,  1.7169, -0.3000, -1.8262],\n         [ 1.0000,  0.7379, -0.0098,  1.7176, -0.2875, -1.8182],\n         [ 1.0000,  0.7379, -0.0098,  1.7182, -0.2750, -1.7058],\n         [ 1.0000,  0.7379, -0.0098,  1.7188, -0.2625, -1.7058],\n         [ 1.0000,  0.7379, -0.0098,  1.7195, -0.2500, -1.6897],\n         [ 1.0000,  0.7379, -0.0098,  1.7201, -0.2375, -1.1279],\n         [ 1.0000,  0.7379, -0.0098,  1.7208, -0.2250, -0.8068],\n         [ 1.0000,  0.7379, -0.0098,  1.7214, -0.2125, -0.6463],\n         [ 1.0000,  0.7379, -0.0098,  1.7221, -0.2000, -0.5941],\n         [ 1.0000,  0.7379, -0.0098,  1.7227, -0.1875, -0.6864],\n         [ 1.0000,  0.7379, -0.0098,  1.7234, -0.1750, -0.4135],\n         [ 1.0000,  0.7379, -0.0098,  1.7240, -0.1625, -0.5499],\n         [ 1.0000,  0.7379, -0.0098,  1.7246, -0.1500, -0.4135],\n         [ 1.0000,  0.7379, -0.0098,  1.7253, -0.1375, -0.6101],\n         [ 1.0000,  0.7379, -0.0098,  1.7259, -0.1250, -0.5539],\n         [ 1.0000,  0.7379, -0.0098,  1.7266, -0.1125, -0.5539],\n         [ 1.0000,  0.7379, -0.0098,  1.7272, -0.1000, -0.5339],\n         [ 1.0000,  0.7379, -0.0098,  1.7279, -0.0875, -0.3854],\n         [ 1.0000,  0.7379, -0.0098,  1.7285, -0.0750, -0.5539],\n         [ 1.0000,  0.7379, -0.0098,  1.7292, -0.0625, -0.4135],\n         [ 1.0000,  0.7379, -0.0098,  1.7298, -0.0500, -0.3172],\n         [ 1.0000,  0.7379, -0.0098,  1.7304, -0.0375, -0.4255],\n         [ 1.0000,  0.7379, -0.0098,  1.7311, -0.0250, -0.3733],\n         [ 1.0000,  0.7379, -0.0098,  1.7317, -0.0125, -0.3573]]],\n       device='cuda:0'), 'encoder_target': tensor([[5.2132, 5.1544, 5.3676, 5.3971, 5.4338, 5.5074, 5.9485, 5.3603, 5.5441,\n         5.7500, 5.5441, 5.7941, 5.7206, 5.7868, 5.8824, 5.9044, 5.9412, 6.0662,\n         6.0441, 6.0588, 6.1397, 6.1397, 6.1324, 6.2500, 6.2059, 6.2868, 6.4485,\n         6.4118, 6.4118, 6.6397, 6.8603, 6.6397, 6.5368, 6.6103, 7.1838, 7.1103,\n         6.7868, 6.7647, 6.9779, 6.9559, 7.4265, 7.0735, 7.5588, 7.1912, 7.3235,\n         7.4044, 7.3603, 7.4044, 1.5809, 1.5441, 1.7132, 1.5441, 1.5294, 1.8382,\n         1.5809, 2.0074, 1.6912, 1.7059, 1.9118, 1.9118, 1.9412, 2.9706, 3.5588,\n         3.8529, 3.9485, 3.7794, 4.2794, 4.0294, 4.2794, 3.9191, 4.0221, 4.0221,\n         4.0588, 4.3309, 4.0221, 4.2794, 4.4559, 4.2574, 4.3529, 4.3824]],\n       device='cuda:0'), 'encoder_lengths': tensor([80], device='cuda:0'), 'decoder_cat': tensor([], device='cuda:0', size=(1, 20, 0), dtype=torch.int64), 'decoder_cont': tensor([[[ 1.0000,  0.7379, -0.0098,  1.7324,  0.0000, -0.3011],\n         [ 1.0000,  0.7379, -0.0098,  1.7330,  0.0125, -0.2449],\n         [ 1.0000,  0.7379, -0.0098,  1.7337,  0.0250, -0.3091],\n         [ 1.0000,  0.7379, -0.0098,  1.7343,  0.0375, -0.3974],\n         [ 1.0000,  0.7379, -0.0098,  1.7349,  0.0500, -0.2851],\n         [ 1.0000,  0.7379, -0.0098,  1.7356,  0.0625, -0.1887],\n         [ 1.0000,  0.7379, -0.0098,  1.7362,  0.0750, -0.2128],\n         [ 1.0000,  0.7379, -0.0098,  1.7369,  0.0875,  0.0842],\n         [ 1.0000,  0.7379, -0.0098,  1.7375,  0.1000,  0.0681],\n         [ 1.0000,  0.7379, -0.0098,  1.7382,  0.1125,  0.1805],\n         [ 1.0000,  0.7379, -0.0098,  1.7388,  0.1250,  0.0119],\n         [ 1.0000,  0.7379, -0.0098,  1.7395,  0.1375,  0.3852],\n         [ 1.0000,  0.7379, -0.0098,  1.7401,  0.1500,  0.2206],\n         [ 1.0000,  0.7379, -0.0098,  1.7407,  0.1625,  0.5096],\n         [ 1.0000,  0.7379, -0.0098,  1.7414,  0.1750,  0.2768],\n         [ 1.0000,  0.7379, -0.0098,  1.7420,  0.1875,  0.4012],\n         [ 1.0000,  0.7379, -0.0098,  1.7427,  0.2000,  0.2768],\n         [ 1.0000,  0.7379, -0.0098,  1.7433,  0.2125,  0.6461],\n         [ 1.0000,  0.7379, -0.0098,  1.7440,  0.2250,  0.4735],\n         [ 1.0000,  0.7379, -0.0098,  1.7446,  0.2375,  0.2768]]],\n       device='cuda:0'), 'decoder_target': tensor([[4.4853, 4.5882, 4.4706, 4.3088, 4.5147, 4.6912, 4.6471, 5.1912, 5.1618,\n         5.3676, 5.0588, 5.7426, 5.4412, 5.9706, 5.5441, 5.7721, 5.5441, 6.2206,\n         5.9044, 5.5441]], device='cuda:0'), 'decoder_lengths': tensor([20], device='cuda:0'), 'decoder_time_idx': tensor([[5377, 5378, 5379, 5380, 5381, 5382, 5383, 5384, 5385, 5386, 5387, 5388,\n         5389, 5390, 5391, 5392, 5393, 5394, 5395, 5396]], device='cuda:0'), 'groups': tensor([[0]], device='cuda:0'), 'target_scale': tensor([[5.0369, 1.8321]], device='cuda:0')}, index=None, decoder_lengths=None, y=None)"}
